{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e33a5774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler ,RobustScaler\n",
    "from sklearn.metrics import mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64975ac",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe7728ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2055 entries, 0 to 2054\n",
      "Data columns (total 46 columns):\n",
      " #   Column               Non-Null Count  Dtype         \n",
      "---  ------               --------------  -----         \n",
      " 0   ds                   2055 non-null   datetime64[ns]\n",
      " 1   SPY_Close            2055 non-null   float64       \n",
      " 2   SPY_Volume           2055 non-null   int64         \n",
      " 3   AAPL                 2055 non-null   float64       \n",
      " 4   MSFT                 2055 non-null   float64       \n",
      " 5   GOOG                 2055 non-null   float64       \n",
      " 6   GLD                  2055 non-null   float64       \n",
      " 7   SLV                  2055 non-null   float64       \n",
      " 8   ^TNX                 2055 non-null   float64       \n",
      " 9   DX-Y.NYB             2055 non-null   float64       \n",
      " 10  JPY=X                2055 non-null   float64       \n",
      " 11  EUR=X                2055 non-null   float64       \n",
      " 12  USO                  2055 non-null   float64       \n",
      " 13  UNG                  2055 non-null   float64       \n",
      " 14  BTC-USD              2055 non-null   float64       \n",
      " 15  CPER                 2055 non-null   float64       \n",
      " 16  ^VIX                 2055 non-null   float64       \n",
      " 17  ^GDAXI               2055 non-null   float64       \n",
      " 18  ^FTSE                2055 non-null   float64       \n",
      " 19  ^RUT                 2055 non-null   float64       \n",
      " 20  ^N225                2055 non-null   float64       \n",
      " 21  IEI                  2055 non-null   float64       \n",
      " 22  CNYUSD=X             2055 non-null   float64       \n",
      " 23  2Y_Yield             2055 non-null   float64       \n",
      " 24  yield_curve          2055 non-null   float64       \n",
      " 25  market_closed_count  2055 non-null   int64         \n",
      " 26  yield_curve_term     2055 non-null   float64       \n",
      " 27  high-low             2055 non-null   float64       \n",
      " 28  before_high-low      2055 non-null   float64       \n",
      " 29  SPY_RSI              2055 non-null   float64       \n",
      " 30  RSI_rank             2055 non-null   float64       \n",
      " 31  RSI_rank_2           2055 non-null   int64         \n",
      " 32  EMA_20               2055 non-null   float64       \n",
      " 33  EMA_50               2055 non-null   float64       \n",
      " 34  EMA_200              2055 non-null   float64       \n",
      " 35  EMA_20_50            2055 non-null   int64         \n",
      " 36  EMA_50_200           2055 non-null   int64         \n",
      " 37  EMA_50_diff          2055 non-null   float64       \n",
      " 38  EMA_200_diff         2055 non-null   float64       \n",
      " 39  SPY_std              2055 non-null   float64       \n",
      " 40  SPY_mean             2055 non-null   float64       \n",
      " 41  SPY_30               2055 non-null   float64       \n",
      " 42  QQQ_Close            2055 non-null   float64       \n",
      " 43  QQQ_Volume           2055 non-null   int64         \n",
      " 44  qqq_std              2055 non-null   float64       \n",
      " 45  qqq_mean             2055 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(39), int64(6)\n",
      "memory usage: 738.6 KB\n"
     ]
    }
   ],
   "source": [
    "SPY = pd.read_pickle('combined_cleaned_add_with_QQQ.pkl')\n",
    "SPY.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80bc794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ds', 'SPY_Close', 'SPY_Volume', 'AAPL', 'MSFT', 'GOOG', 'GLD', 'SLV', '^TNX', 'DX-Y.NYB', 'JPY=X', 'EUR=X', 'USO', 'UNG', 'BTC-USD', 'CPER', '^VIX', '^GDAXI', '^FTSE', '^RUT', '^N225', 'IEI', 'CNYUSD=X', '2Y_Yield', 'yield_curve', 'market_closed_count', 'yield_curve_term', 'high-low', 'before_high-low', 'SPY_RSI', 'RSI_rank', 'RSI_rank_2', 'EMA_20', 'EMA_50', 'EMA_200', 'EMA_20_50', 'EMA_50_200', 'EMA_50_diff', 'EMA_200_diff', 'SPY_std', 'SPY_mean', 'SPY_30', 'QQQ_Close', 'QQQ_Volume', 'qqq_std', 'qqq_mean']\n"
     ]
    }
   ],
   "source": [
    "print(SPY.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1572355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rsi(prices, period=14):\n",
    "    prices = pd.to_numeric(prices, errors='coerce')\n",
    "    delta  = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "  # MACD Calculation\n",
    "def calculate_macd(prices, fast=12, slow=26):\n",
    "    prices = pd.Series(prices).astype(float).dropna()\n",
    "    exp1 = prices.ewm(span=fast, adjust=False).mean()\n",
    "    exp2 = prices.ewm(span=slow, adjust=False).mean()\n",
    "    return exp1 - exp2\n",
    "    \n",
    "def calculate_consecutive_streak(close_series: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Calculate the consecutive up/down streaks for a close price series.\n",
    "    - If today's close > yesterday's, streak = previous_streak + 1 (or 1 if previous_streak <= 0)\n",
    "    - If today's close < yesterday's, streak = previous_streak - 1 (or -1 if previous_streak >= 0)\n",
    "    - If equal, streak = 0\n",
    "    \"\"\"\n",
    "    streak = [0] * len(close_series)\n",
    "    for i in range(1, len(close_series)):\n",
    "        if close_series.iat[i] > close_series.iat[i - 1]:\n",
    "            streak[i] = streak[i - 1] + 1 if streak[i - 1] > 0 else 1\n",
    "        elif close_series.iat[i] < close_series.iat[i - 1]:\n",
    "            streak[i] = streak[i - 1] - 1 if streak[i - 1] < 0 else -1\n",
    "        else:\n",
    "            streak[i] = 0\n",
    "    return pd.Series(streak, index=close_series.index, name='consecutive_streak')\n",
    "\n",
    "\n",
    "def model_own_features(\n",
    "    data: pd.DataFrame,\n",
    "    column: str,\n",
    "    keep_columns = None\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add RSI, MACD, rolling means, std, and consecutive streak for `column`.\n",
    "    Optionally preserve only keep_columns + new features.\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    # Ensure numeric\n",
    "    df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "    \n",
    "    # 1) RSI\n",
    "    df['RSI_14'] = calculate_rsi(df[column], period=14)\n",
    "    \n",
    "    # 2) MACD\n",
    "    #macd_df = calculate_macd(df[column])\n",
    "    #df = df.join(macd_df)\n",
    "    df['MACD'] = calculate_macd(df[column])\n",
    "    # 3) Rolling stats\n",
    "    df['30d_mean'] = df[column].rolling(30).mean()\n",
    "    df['5d_mean']  = df[column].rolling(5).mean()\n",
    "    df['5d_std']   = df[column].rolling(5).std()\n",
    "    \n",
    "    # 4) Consecutive streak\n",
    "    df['streak'] = calculate_consecutive_streak(df[column])\n",
    "    \n",
    "    # 5) Select output columns\n",
    "    if keep_columns is not None:\n",
    "        # always include the new features\n",
    "        new_feats = ['RSI_14', 'MACD', '30d_mean', '5d_mean', '5d_std', 'streak']\n",
    "        df = df[ keep_columns + new_feats ]\n",
    "\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4028afed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2026 entries, 29 to 2054\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   SPY_Close        2026 non-null   float64\n",
      " 1   high-low         2026 non-null   float64\n",
      " 2   before_high-low  2026 non-null   float64\n",
      " 3   RSI_14           2026 non-null   float64\n",
      " 4   MACD             2026 non-null   float64\n",
      " 5   30d_mean         2026 non-null   float64\n",
      " 6   5d_mean          2026 non-null   float64\n",
      " 7   5d_std           2026 non-null   float64\n",
      " 8   streak           2026 non-null   int64  \n",
      "dtypes: float64(8), int64(1)\n",
      "memory usage: 158.3 KB\n"
     ]
    }
   ],
   "source": [
    "result = model_own_features(\n",
    "    data=SPY,\n",
    "    column='SPY_Close',\n",
    "    keep_columns=['SPY_Close','high-low','before_high-low']\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "result.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5b6de203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPY_Close</th>\n",
       "      <th>high-low</th>\n",
       "      <th>before_high-low</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>MACD</th>\n",
       "      <th>30d_mean</th>\n",
       "      <th>5d_mean</th>\n",
       "      <th>5d_std</th>\n",
       "      <th>streak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2358.570068</td>\n",
       "      <td>26.150146</td>\n",
       "      <td>22.649902</td>\n",
       "      <td>47.955152</td>\n",
       "      <td>-2.163017</td>\n",
       "      <td>2364.098332</td>\n",
       "      <td>2347.710010</td>\n",
       "      <td>6.574907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2361.129883</td>\n",
       "      <td>10.420166</td>\n",
       "      <td>26.150146</td>\n",
       "      <td>48.276382</td>\n",
       "      <td>-1.700607</td>\n",
       "      <td>2364.883325</td>\n",
       "      <td>2350.245996</td>\n",
       "      <td>8.948561</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2368.060059</td>\n",
       "      <td>11.839844</td>\n",
       "      <td>10.420166</td>\n",
       "      <td>47.892270</td>\n",
       "      <td>-0.766106</td>\n",
       "      <td>2365.510327</td>\n",
       "      <td>2354.666016</td>\n",
       "      <td>11.419225</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2362.719971</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>11.839844</td>\n",
       "      <td>45.208163</td>\n",
       "      <td>-0.451207</td>\n",
       "      <td>2366.026994</td>\n",
       "      <td>2358.414014</td>\n",
       "      <td>10.025371</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2358.840088</td>\n",
       "      <td>21.140137</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>46.940722</td>\n",
       "      <td>-0.508855</td>\n",
       "      <td>2366.283000</td>\n",
       "      <td>2361.864014</td>\n",
       "      <td>3.861890</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SPY_Close   high-low  before_high-low     RSI_14      MACD     30d_mean  \\\n",
       "0  2358.570068  26.150146        22.649902  47.955152 -2.163017  2364.098332   \n",
       "1  2361.129883  10.420166        26.150146  48.276382 -1.700607  2364.883325   \n",
       "2  2368.060059  11.839844        10.420166  47.892270 -0.766106  2365.510327   \n",
       "3  2362.719971   7.750000        11.839844  45.208163 -0.451207  2366.026994   \n",
       "4  2358.840088  21.140137         7.750000  46.940722 -0.508855  2366.283000   \n",
       "\n",
       "       5d_mean     5d_std  streak  \n",
       "0  2347.710010   6.574907       1  \n",
       "1  2350.245996   8.948561       2  \n",
       "2  2354.666016  11.419225       3  \n",
       "3  2358.414014  10.025371      -1  \n",
       "4  2361.864014   3.861890      -2  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.reset_index(drop=True)\n",
    "\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c029b8",
   "metadata": {},
   "source": [
    "### Creat a sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e8eb0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences_multifeature(data, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(window_size, len(data)):\n",
    "        X.append(data[i - window_size:i])\n",
    "        y.append(data[i, 0])  # תחזית רק למחיר\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size = 30\n",
    "#X, y = create_sequences_multifeature(scaled_data, window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85ddeef",
   "metadata": {},
   "source": [
    "### Scaling, Creating a sequence & spliting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb877c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler() # scale the data\n",
    "def prepare_RNN_data(data,window_size,scaler,split_ratio=0.8):\n",
    "    \n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "    X, y = create_sequences_multifeature(scaled_data, window_size)\n",
    "    split = int(split_ratio * len(X))\n",
    "    X_train, X_test = X[:split], X[split:]\n",
    "    y_train, y_test = y[:split], y[split:]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a2af3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 30\n",
    "X_train, X_test, y_train, y_test = prepare_RNN_data(result, 30,scaler) # for sequence length of 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dc8b79",
   "metadata": {},
   "source": [
    "# Search for the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3dbabd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def search_best_model(\n",
    "    model_type: str,\n",
    "    X_train, y_train,\n",
    "    X_val, y_val,\n",
    "    window_size: int,\n",
    "    layer_options=(1, 2, 3),\n",
    "    unit_options=(32, 64, 98),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    patience=3,\n",
    "    learning_rate=0.001\n",
    "):\n",
    "    \"\"\"\n",
    "    Grid‐search over small GRU/LSTM architectures to minimize validation MSE.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model_type : {\"GRU\", \"LSTM\"}\n",
    "        Which recurrent cell to use.\n",
    "    X_train, y_train : np.ndarray\n",
    "        Training data.\n",
    "    X_val, y_val : np.ndarray\n",
    "        Validation data.\n",
    "    window_size : int\n",
    "        Number of timesteps in each input sequence.\n",
    "    layer_options : iterable of int\n",
    "        You’ll try each of these as possible numbers of recurrent layers.\n",
    "    unit_options : iterable of int\n",
    "        Possible unit‐counts for each layer.\n",
    "    epochs : int\n",
    "        Maximum epochs per architecture.\n",
    "    batch_size : int\n",
    "    patience : int\n",
    "        EarlyStopping patience on val_loss.\n",
    "    learning_rate : float\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    best_model : keras.Model\n",
    "        The model instance that achieved the lowest val_loss.\n",
    "    best_val_loss : float\n",
    "        Its validation loss.\n",
    "    best_config : (n_layers, units_tuple)\n",
    "        The layer‐count and the specific units in each layer.\n",
    "    \"\"\"\n",
    "    if model_type not in (\"GRU\", \"LSTM\"):\n",
    "        raise ValueError(f\"model_type must be 'GRU' or 'LSTM', got {model_type!r}\")\n",
    "    Cell = GRU if model_type == \"GRU\" else LSTM\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_model     = None\n",
    "    best_config    = None\n",
    "\n",
    "    for n_layers in layer_options:\n",
    "        for units_combo in itertools.product(unit_options, repeat=n_layers):\n",
    "            # Build model\n",
    "            model = Sequential()\n",
    "            for i, units in enumerate(units_combo):\n",
    "                return_seq = (i < n_layers - 1)\n",
    "                if i == 0:\n",
    "                    model.add(\n",
    "                        Cell(\n",
    "                            units,\n",
    "                            return_sequences=return_seq,\n",
    "                            input_shape=(window_size, X_train.shape[2])\n",
    "                        )\n",
    "                    )\n",
    "                else:\n",
    "                    model.add(Cell(units, return_sequences=return_seq))\n",
    "            model.add(Dense(1))\n",
    "\n",
    "            # Compile & train\n",
    "            opt = Adam(learning_rate=learning_rate)\n",
    "            model.compile(optimizer=opt, loss=\"mse\")\n",
    "            es = EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=patience,\n",
    "                restore_best_weights=True\n",
    "            )\n",
    "            history = model.fit(\n",
    "                X_train, y_train,\n",
    "                validation_data=(X_val, y_val),\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                callbacks=[es],\n",
    "                verbose=0\n",
    "            )\n",
    "\n",
    "            val_loss = min(history.history[\"val_loss\"])\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                best_config   = (n_layers, units_combo)\n",
    "                best_model    = model\n",
    "\n",
    "    return best_model, best_val_loss, best_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc33ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model, best_loss, best_cfg = search_best_model(\n",
    "    model_type=\"GRU\",                # or \"LSTM\"\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    X_val=X_test,  y_val=y_test,\n",
    "    window_size=window_size,\n",
    "    layer_options=[1,2,3],\n",
    "    unit_options=[32,64,98],\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    patience=3,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "print(\"Best loss:\", best_loss, \"Config:\", best_cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1bb493",
   "metadata": {},
   "source": [
    "# Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f51d217",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_lstm(\n",
    "    X_train, y_train,\n",
    "    learning_rate=0.001,\n",
    "    epochs=20,\n",
    "    num_layers=1,\n",
    "    units=(64,),\n",
    "    window_size=None,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    patience=3,\n",
    "    checkpoint_path='best_lstm.h5',\n",
    "    dense_units=None,\n",
    "    dense_activation='relu'\n",
    "):\n",
    "    \"\"\"\n",
    "    Builds, compiles, and trains a multi-layer LSTM model, with optional intermediate Dense layer.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train, y_train: training data arrays\n",
    "    - learning_rate: float, optimizer learning rate\n",
    "    - epochs: int, max training epochs\n",
    "    - num_layers: int, number of LSTM layers\n",
    "    - units: tuple of ints, units per LSTM layer (length must equal num_layers)\n",
    "    - window_size: int, sequence length (timesteps)\n",
    "    - batch_size: int\n",
    "    - validation_split: float\n",
    "    - patience: int, early stopping patience\n",
    "    - checkpoint_path: str, filepath to save best model\n",
    "    - dense_units: int or None, if specified adds Dense(dense_units, activation=dense_activation)\n",
    "    - dense_activation: str, activation for the optional Dense layer\n",
    "\n",
    "    Returns:\n",
    "    - model: trained Keras model\n",
    "    - history: training history\n",
    "    \"\"\"\n",
    "    if num_layers != len(units):\n",
    "        raise ValueError(f\"num_layers ({num_layers}) must equal length of units tuple ({len(units)})\")\n",
    "    \n",
    "    opt = Adam(learning_rate=learning_rate)\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add LSTM layers\n",
    "    for i, u in enumerate(units):\n",
    "        return_seq = (i < num_layers - 1)\n",
    "        if i == 0:\n",
    "            model.add(LSTM(u, return_sequences=return_seq, input_shape=(window_size, X_train.shape[2])))\n",
    "        else:\n",
    "            model.add(LSTM(u, return_sequences=return_seq))\n",
    "    \n",
    "    # Optional Dense layer\n",
    "    if dense_units is not None:\n",
    "        model.add(Dense(dense_units, activation=dense_activation))\n",
    "    # Output layer\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile(optimizer=opt, loss='mse')\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    chk = ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss',\n",
    "                          save_best_only=True, verbose=1)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=[es, chk],\n",
    "        verbose=1\n",
    "    )\n",
    "    return model, history\n",
    "\n",
    "def train_gru(\n",
    "    X_train, y_train,\n",
    "    learning_rate=0.001,\n",
    "    epochs=20,\n",
    "    num_layers=1,\n",
    "    units=(64,),\n",
    "    window_size=None,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    patience=3,\n",
    "    checkpoint_path='best_gru.h5',\n",
    "    dense_units=None,\n",
    "    dense_activation='relu'\n",
    "):\n",
    "    \"\"\"\n",
    "    Builds, compiles, and trains a multi-layer GRU model (on GPU if available), with optional Dense layer.\n",
    "\n",
    "    Parameters: same as train_lstm.\n",
    "    \"\"\"\n",
    "    if num_layers != len(units):\n",
    "        raise ValueError(f\"num_layers ({num_layers}) must equal length of units tuple ({len(units)})\")\n",
    "    \n",
    "    # Choose device\n",
    "    device = '/GPU:0' if tf.config.list_physical_devices('GPU') else '/CPU:0'\n",
    "    with tf.device(device):\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "        model = Sequential()\n",
    "        # Add GRU layers\n",
    "        for i, u in enumerate(units):\n",
    "            return_seq = (i < num_layers - 1)\n",
    "            if i == 0:\n",
    "                model.add(GRU(u, return_sequences=return_seq, input_shape=(window_size, X_train.shape[2])))\n",
    "            else:\n",
    "                model.add(GRU(u, return_sequences=return_seq))\n",
    "        # Optional Dense layer\n",
    "        if dense_units is not None:\n",
    "            model.add(Dense(dense_units, activation=dense_activation))\n",
    "        # Output layer\n",
    "        model.add(Dense(1))\n",
    "        model.compile(optimizer=opt, loss='mse')\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss', patience=patience, restore_best_weights=True)\n",
    "    chk = ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss',\n",
    "                          save_best_only=True, verbose=1)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=validation_split,\n",
    "        callbacks=[es, chk],\n",
    "        verbose=1\n",
    "    )\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f53dd99",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e71874d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\OMER\\PycharmProjects\\Project\\.venv\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m79/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0156\n",
      "Epoch 1: val_loss improved from inf to 0.00044, saving model to best_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0153 - val_loss: 4.4078e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m78/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.6145e-04\n",
      "Epoch 2: val_loss improved from 0.00044 to 0.00034, saving model to best_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.6087e-04 - val_loss: 3.4470e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m78/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0350e-04\n",
      "Epoch 3: val_loss improved from 0.00034 to 0.00031, saving model to best_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 2.0366e-04 - val_loss: 3.0921e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m78/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8032e-04\n",
      "Epoch 4: val_loss did not improve from 0.00031\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8087e-04 - val_loss: 3.1472e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m78/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.9473e-04\n",
      "Epoch 5: val_loss improved from 0.00031 to 0.00030, saving model to best_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.9353e-04 - val_loss: 2.9593e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m77/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8309e-04\n",
      "Epoch 6: val_loss improved from 0.00030 to 0.00027, saving model to best_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.8269e-04 - val_loss: 2.7056e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m78/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7074e-04\n",
      "Epoch 7: val_loss did not improve from 0.00027\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7196e-04 - val_loss: 3.3660e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m78/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5990e-04\n",
      "Epoch 8: val_loss improved from 0.00027 to 0.00025, saving model to best_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6083e-04 - val_loss: 2.5091e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m77/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7402e-04\n",
      "Epoch 9: val_loss did not improve from 0.00025\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7419e-04 - val_loss: 2.5691e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m72/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4635e-04\n",
      "Epoch 10: val_loss did not improve from 0.00025\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4712e-04 - val_loss: 2.7361e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m73/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8406e-04\n",
      "Epoch 11: val_loss did not improve from 0.00025\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.8456e-04 - val_loss: 4.1882e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m78/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8263e-04\n",
      "Epoch 12: val_loss improved from 0.00025 to 0.00024, saving model to best_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.8224e-04 - val_loss: 2.4162e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m77/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5327e-04\n",
      "Epoch 13: val_loss did not improve from 0.00024\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5389e-04 - val_loss: 3.0615e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m77/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7135e-04\n",
      "Epoch 14: val_loss did not improve from 0.00024\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7108e-04 - val_loss: 3.7081e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m78/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.7409e-04\n",
      "Epoch 15: val_loss improved from 0.00024 to 0.00023, saving model to best_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.7363e-04 - val_loss: 2.3091e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m78/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5894e-04\n",
      "Epoch 16: val_loss improved from 0.00023 to 0.00022, saving model to best_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5905e-04 - val_loss: 2.1803e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m77/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4652e-04\n",
      "Epoch 17: val_loss improved from 0.00022 to 0.00021, saving model to best_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4588e-04 - val_loss: 2.0622e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m78/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8104e-04\n",
      "Epoch 18: val_loss did not improve from 0.00021\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8061e-04 - val_loss: 3.5404e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m78/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.6596e-04\n",
      "Epoch 19: val_loss improved from 0.00021 to 0.00020, saving model to best_lstm.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.6562e-04 - val_loss: 1.9930e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m78/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.5597e-04\n",
      "Epoch 20: val_loss did not improve from 0.00020\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5591e-04 - val_loss: 2.0395e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m78/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.3390e-04\n",
      "Epoch 21: val_loss did not improve from 0.00020\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3426e-04 - val_loss: 4.3304e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m72/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4181e-04\n",
      "Epoch 22: val_loss did not improve from 0.00020\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 1.4116e-04 - val_loss: 2.8013e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m79/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.8567e-04\n",
      "Epoch 23: val_loss did not improve from 0.00020\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.8548e-04 - val_loss: 2.0812e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m75/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4060e-04\n",
      "Epoch 24: val_loss did not improve from 0.00020\n",
      "\u001b[1m80/80\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4113e-04 - val_loss: 2.4499e-04\n"
     ]
    }
   ],
   "source": [
    "model_lstm = train_lstm(\n",
    "    X_train, y_train,\n",
    "    learning_rate=0.004,\n",
    "    epochs=30,\n",
    "    num_layers=1,\n",
    "    units=(90,),\n",
    "    window_size=30,\n",
    "    batch_size=16,\n",
    "    validation_split=0.2,\n",
    "    patience=5,\n",
    "    checkpoint_path='best_lstm.h5',\n",
    "    dense_units=None,\n",
    "    dense_activation='relu'\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f103f01",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bd85bb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0375\n",
      "Epoch 1: val_loss improved from inf to 0.00058, saving model to best_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0370 - val_loss: 5.7643e-04\n",
      "Epoch 2/30\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.8027e-04\n",
      "Epoch 2: val_loss improved from 0.00058 to 0.00045, saving model to best_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.7793e-04 - val_loss: 4.4612e-04\n",
      "Epoch 3/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.0267e-04\n",
      "Epoch 3: val_loss improved from 0.00045 to 0.00025, saving model to best_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 2.0224e-04 - val_loss: 2.4518e-04\n",
      "Epoch 4/30\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7198e-04\n",
      "Epoch 4: val_loss did not improve from 0.00025\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7023e-04 - val_loss: 2.5169e-04\n",
      "Epoch 5/30\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.5346e-04\n",
      "Epoch 5: val_loss improved from 0.00025 to 0.00023, saving model to best_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.5254e-04 - val_loss: 2.3319e-04\n",
      "Epoch 6/30\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4273e-04\n",
      "Epoch 6: val_loss improved from 0.00023 to 0.00021, saving model to best_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4278e-04 - val_loss: 2.0523e-04\n",
      "Epoch 7/30\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4827e-04\n",
      "Epoch 7: val_loss did not improve from 0.00021\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4697e-04 - val_loss: 2.2678e-04\n",
      "Epoch 8/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3276e-04\n",
      "Epoch 8: val_loss improved from 0.00021 to 0.00019, saving model to best_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3267e-04 - val_loss: 1.9463e-04\n",
      "Epoch 9/30\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2718e-04\n",
      "Epoch 9: val_loss did not improve from 0.00019\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2691e-04 - val_loss: 1.9587e-04\n",
      "Epoch 10/30\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3472e-04\n",
      "Epoch 10: val_loss did not improve from 0.00019\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3420e-04 - val_loss: 1.9464e-04\n",
      "Epoch 11/30\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3950e-04\n",
      "Epoch 11: val_loss improved from 0.00019 to 0.00019, saving model to best_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.3955e-04 - val_loss: 1.9110e-04\n",
      "Epoch 12/30\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3652e-04\n",
      "Epoch 12: val_loss did not improve from 0.00019\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3659e-04 - val_loss: 2.0178e-04\n",
      "Epoch 13/30\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0457e-04\n",
      "Epoch 13: val_loss did not improve from 0.00019\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0566e-04 - val_loss: 1.9241e-04\n",
      "Epoch 14/30\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3265e-04\n",
      "Epoch 14: val_loss did not improve from 0.00019\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3351e-04 - val_loss: 2.3435e-04\n",
      "Epoch 15/30\n",
      "\u001b[1m34/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4468e-04\n",
      "Epoch 15: val_loss improved from 0.00019 to 0.00018, saving model to best_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4345e-04 - val_loss: 1.8489e-04\n",
      "Epoch 16/30\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0752e-04\n",
      "Epoch 16: val_loss did not improve from 0.00018\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0825e-04 - val_loss: 2.0743e-04\n",
      "Epoch 17/30\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2975e-04\n",
      "Epoch 17: val_loss did not improve from 0.00018\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2938e-04 - val_loss: 1.9527e-04\n",
      "Epoch 18/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1762e-04\n",
      "Epoch 18: val_loss improved from 0.00018 to 0.00018, saving model to best_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1755e-04 - val_loss: 1.8089e-04\n",
      "Epoch 19/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.1694e-04\n",
      "Epoch 19: val_loss did not improve from 0.00018\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1690e-04 - val_loss: 1.9947e-04\n",
      "Epoch 20/30\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2687e-04\n",
      "Epoch 20: val_loss did not improve from 0.00018\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2723e-04 - val_loss: 1.8821e-04\n",
      "Epoch 21/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 1.4108e-04\n",
      "Epoch 21: val_loss improved from 0.00018 to 0.00018, saving model to best_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.4088e-04 - val_loss: 1.7548e-04\n",
      "Epoch 22/30\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.1848e-04\n",
      "Epoch 22: val_loss did not improve from 0.00018\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.1912e-04 - val_loss: 1.9594e-04\n",
      "Epoch 23/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.4624e-04\n",
      "Epoch 23: val_loss did not improve from 0.00018\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.4611e-04 - val_loss: 1.7950e-04\n",
      "Epoch 24/30\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2065e-04\n",
      "Epoch 24: val_loss did not improve from 0.00018\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2056e-04 - val_loss: 1.8043e-04\n",
      "Epoch 25/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2192e-04\n",
      "Epoch 25: val_loss improved from 0.00018 to 0.00017, saving model to best_gru.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.2214e-04 - val_loss: 1.7426e-04\n",
      "Epoch 26/30\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.0345e-04\n",
      "Epoch 26: val_loss did not improve from 0.00017\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.0631e-04 - val_loss: 1.8468e-04\n",
      "Epoch 27/30\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.2136e-04\n",
      "Epoch 27: val_loss did not improve from 0.00017\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.2186e-04 - val_loss: 2.8769e-04\n",
      "Epoch 28/30\n",
      "\u001b[1m37/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3673e-04\n",
      "Epoch 28: val_loss did not improve from 0.00017\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3545e-04 - val_loss: 2.2967e-04\n",
      "Epoch 29/30\n",
      "\u001b[1m38/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.7277e-04\n",
      "Epoch 29: val_loss did not improve from 0.00017\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.7095e-04 - val_loss: 1.9321e-04\n",
      "Epoch 30/30\n",
      "\u001b[1m39/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 1.3450e-04\n",
      "Epoch 30: val_loss did not improve from 0.00017\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 1.3368e-04 - val_loss: 1.7902e-04\n"
     ]
    }
   ],
   "source": [
    "model_gru = train_gru(\n",
    "    X_train, y_train,\n",
    "    learning_rate=0.004,\n",
    "    epochs=30,\n",
    "    num_layers=1,\n",
    "    units=(96,),\n",
    "    window_size=30,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    patience=5,\n",
    "    checkpoint_path='best_gru.h5',\n",
    "    dense_units=None,\n",
    "    dense_activation='relu'\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d2ebbe",
   "metadata": {},
   "source": [
    "### Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5079c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 1. Point to the same filepath you used in ModelCheckpoint\n",
    "checkpoint_path = \"best_lstm.h5\"   # or \"best_gru.h5\", etc.\n",
    "\n",
    "# 2. Load the entire model (architecture + weights + optimizer state)\n",
    "best_model = load_model(checkpoint_path)\n",
    "\n",
    "# 3. Now you can call .predict(), .evaluate(), etc.\n",
    "preds = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23266c1d",
   "metadata": {},
   "source": [
    "## Making a prediction and inversing the scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b63cb609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    }
   ],
   "source": [
    "pred_lstm = model_lstm.predict(X_test)\n",
    "pred_gru = model_gru.predict(X_test)\n",
    "\n",
    "# reset the scaler to the original price range\n",
    "price_scaler = MinMaxScaler()\n",
    "price_scaler.min_, price_scaler.scale_ = scaler.min_[0], scaler.scale_[0]\n",
    "pred_lstm = price_scaler.inverse_transform(pred_lstm)\n",
    "pred_gru = price_scaler.inverse_transform(pred_gru)\n",
    "y_test_actual = price_scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "#y_test_actual = price_scaler.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0790fada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM - MSE: 8779.4122, R²: 0.9705\n",
      "GRU  - MSE: 5392.4582, R²: 0.9819\n"
     ]
    }
   ],
   "source": [
    "mse_lstm = mean_squared_error(y_test_actual, pred_lstm)\n",
    "mse_gru = mean_squared_error(y_test_actual, pred_gru)\n",
    "\n",
    "r2_lstm = r2_score(y_test_actual, pred_lstm)\n",
    "r2_gru = r2_score(y_test_actual, pred_gru)\n",
    "\n",
    "print(f'LSTM - MSE: {mse_lstm:.4f}, R²: {r2_lstm:.4f}')\n",
    "print(f'GRU  - MSE: {mse_gru:.4f}, R²: {r2_gru:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
